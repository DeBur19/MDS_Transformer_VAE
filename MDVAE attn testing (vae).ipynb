{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vaXDWiB3B2Xp"
   },
   "outputs": [],
   "source": [
    "pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10387,
     "status": "ok",
     "timestamp": 1589908444278,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "9L42Nu5AB2Xy",
    "outputId": "d404a054-35cf-4718-fa1a-9da90c777ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yd_pGIi3B2X4"
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "0d0f78ce177140c1b9a040a346ad2010",
      "a2bce06c77fc4cf5b550cb99de9c4492",
      "1ac5121ecf1f49d7b2350f1ba868030f",
      "ca7e3ea397814abba8c20bbbb7b215f5",
      "ecbf5dae3bea42c484d0fa3ad955024d",
      "1ad0a59ed03e409fbe018c6e886f6b92",
      "a81972552cbf4ad0a13c7a40e41963c4",
      "1788b3958b344224a5e50de99ad57c8a"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12024,
     "status": "ok",
     "timestamp": 1589908446335,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "UYz7xVqrB2YG",
    "outputId": "f56f6f3c-cb49-4724-d5b3-13fda0188503"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0f78ce177140c1b9a040a346ad2010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JO2JZo3sB2X7"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "DEC_SOS_IND = 0\n",
    "DEC_EOS_IND = 1\n",
    "DEC_UNK_IND = 2\n",
    "MAX_SUMMARY_LEN = 502\n",
    "MAX_DOC_LEN = 512\n",
    "N_TRAIN = 44972\n",
    "N_VAL = 5622\n",
    "N_TEST = 5622\n",
    "BERT_DIM = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrXPu6WaFPBn"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6n0-JX_FFZh2"
   },
   "outputs": [],
   "source": [
    "train = torch.load('data/train2.0.pt')\n",
    "val = torch.load('data/val2.0.pt')\n",
    "test = torch.load('data/test2.0.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdnxDzF5B2Yg"
   },
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "23c287216acc4a71b80244f2137c0fde",
      "e27b53c544f041409a376f39bbc67673",
      "6ad92cfc638549d1b21fad4595d427d1",
      "14933fc904ea4ddbb98c35f2fbecf73a",
      "c4eb9bb0ef7f4e2da27f2058caeb670a",
      "09efaf2f3e7f43df9b36d5a72d75be85",
      "6804545ef6ed4f52b8cad1ab07b866dd",
      "548d5ce503ba41819891d08718ae527a",
      "32025c95903c4dc2811ca543b2ff05c8",
      "714669ac5e784e808343438683ac9913",
      "2cbe3ce456a24364a96ed320cc66c47e",
      "1e98a88643d74ad1933416d41c27e6a2",
      "932584e0b8f74b489ac86a39ddf12307",
      "29d4d28987f64112bb8aea24b2b16679",
      "4b791fdb9e724886986d68ff298f9945",
      "94e99194c94347aeaf7996a95d668ea4"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21658,
     "status": "ok",
     "timestamp": 1589908511793,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "c_GYFB5vB2Yg",
    "outputId": "dde97b34-70c4-4dad-80eb-2f01e0ef052b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c287216acc4a71b80244f2137c0fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32025c95903c4dc2811ca543b2ff05c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQM4dOUnB2Yj"
   },
   "outputs": [],
   "source": [
    "bert_model = bert_model.cpu()\n",
    "bert_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SC2ZGbQuB2Yo"
   },
   "outputs": [],
   "source": [
    "def tokenized2batch(data, inds, bert_model, tokenizer):\n",
    "    \n",
    "    def BERTembeds2batch(embeds, sep_inds, first_pad_ind):\n",
    "        if sep_inds.shape[0] == 0:\n",
    "            return embeds[:first_pad_ind].unsqueeze(0), None\n",
    "        batch = []\n",
    "        tmpj = 0\n",
    "        for j in range(sep_inds.shape[0] + 1):\n",
    "            if j != sep_inds.shape[0]:\n",
    "                if sep_inds[j] - tmpj != 0:\n",
    "                    batch.append(embeds[tmpj:sep_inds[j]])\n",
    "                tmpj = sep_inds[j] + 1\n",
    "            else:\n",
    "                batch.append(embeds[tmpj:first_pad_ind])\n",
    "        lens = [s.shape[0] for s in batch]\n",
    "        batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "        pad_mask = torch.ones((batch.shape[0], batch.shape[1]), dtype=bool, device=batch.device)\n",
    "        for i in range(pad_mask.shape[0]):\n",
    "            pad_mask[i, :lens[i]] = False\n",
    "        return batch, pad_mask\n",
    "        \n",
    "    pad_id = tokenizer.encode('[PAD]')[1]\n",
    "    sep_id = tokenizer.encode('[SEP]')[1]\n",
    "    \n",
    "    batch = [0] * inds.shape[0]\n",
    "    first_pad_inds = [0] * inds.shape[0]\n",
    "    for i in range(inds.shape[0]):\n",
    "        batch[i] = data[inds[i]]\n",
    "        offset = 0\n",
    "        while batch[i][-(offset + 1)] == sep_id:\n",
    "            offset += 1\n",
    "        if offset != 0:\n",
    "            batch[i] = batch[i][:offset]\n",
    "        first_pad_inds[i] = batch[i].shape[0]\n",
    "    batch = pad_sequence(batch, batch_first=True, padding_value=pad_id)\n",
    "    \n",
    "    attn_mask = (batch != pad_id).to(torch.float)\n",
    "    \n",
    "    pos = torch.arange(0, batch.shape[1])\n",
    "    pos_ids = torch.zeros_like(batch)\n",
    "    sep_inds = [0] * batch.shape[0]\n",
    "    for i in range(batch.shape[0]):\n",
    "        tmp = pos[batch[i] == sep_id]\n",
    "        sep_inds[i] = tmp\n",
    "        tmpj = 0\n",
    "        for j in range(tmp.shape[0] + 1):\n",
    "            if j != tmp.shape[0]:\n",
    "                pos_ids[i, tmpj:tmp[j] + 1] = pos[:tmp[j] + 1 - tmpj]\n",
    "                tmpj = tmp[j] + 1\n",
    "            else:\n",
    "                pos_ids[i, tmpj:] = pos[:batch.shape[1] - tmpj]\n",
    "                \n",
    "    bert_embeds = None\n",
    "    with torch.no_grad():\n",
    "        model = bert_model.cuda()\n",
    "        batch = batch.cuda()\n",
    "        attn_mask = attn_mask.cuda()\n",
    "        pos_ids = pos_ids.cuda()\n",
    "        bert_embeds = model(batch, attention_mask=attn_mask, position_ids=pos_ids)[0]\n",
    "        del model\n",
    "        del batch\n",
    "        del attn_mask\n",
    "        del pos_ids\n",
    "    \n",
    "    batch = []\n",
    "    for i in range(bert_embeds.shape[0]):\n",
    "        batch.append(BERTembeds2batch(bert_embeds[i], sep_inds[i], first_pad_inds[i]))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APRcRGvXB2Yq"
   },
   "source": [
    "## Tokenizer for summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_TfqxVHB2Yr"
   },
   "outputs": [],
   "source": [
    "class summary_lang():\n",
    "    def __init__(self):\n",
    "        self.word2id = {'<SOS>': DEC_SOS_IND, '<EOS>' : DEC_EOS_IND, '<UNK>' : DEC_UNK_IND}\n",
    "        self.id2word = {DEC_SOS_IND : '<SOS>', DEC_EOS_IND : '<EOS>', DEC_UNK_IND : '<UNK>'}\n",
    "        self.word_counts = {}\n",
    "        self.count = 3\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "        \n",
    "    def add_summaries(self, summaries, counter, thr=3):\n",
    "        for summary in summaries:\n",
    "            for word in summary:\n",
    "                if counter[word] <= thr:\n",
    "                    continue\n",
    "                if word in self.word2id:\n",
    "                    self.word_counts[word] += 1\n",
    "                else:\n",
    "                    self.word2id[word] = self.count\n",
    "                    self.id2word[self.count] = word\n",
    "                    self.count += 1\n",
    "                    self.word_counts[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1vcyCMWHsrQ"
   },
   "source": [
    "## Load vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHVMbiY4HrkP"
   },
   "outputs": [],
   "source": [
    "sum_lang = torch.load('data/vocab2.0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QA0rsa1sB2Yx"
   },
   "outputs": [],
   "source": [
    "dec_vocab_size = len(sum_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2242,
     "status": "ok",
     "timestamp": 1589908514061,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "wMmjmiqVH-Fd",
    "outputId": "baf3437d-825e-4bcf-dd12-b66d5b0219dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49295"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3c03lYbTGclE"
   },
   "source": [
    "## Load tokenized summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZmTXKYKGhFi"
   },
   "outputs": [],
   "source": [
    "train_sum = torch.load('data/train_sum2.0.pt')\n",
    "val_sum = torch.load('data/val_sum2.0.pt')\n",
    "test_sum = torch.load('data/test_sum2.0.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adjInGVMB2ZF"
   },
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TYzv2IRB2ZG"
   },
   "outputs": [],
   "source": [
    "def plot_history(train_history, val_history):\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.title('Full loss (nll + kl)')\n",
    "    plt.plot(train_history[0], label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history[0])\n",
    "    \n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    \n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.title('Nll loss')\n",
    "    plt.plot(train_history[1], label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history[1])\n",
    "    \n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.title('Kl divergence')\n",
    "    plt.plot(train_history[2], label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history[2])\n",
    "    \n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9ojwXyOB2ZI"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InEO0huMB2ZI"
   },
   "outputs": [],
   "source": [
    "# from https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.0, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCSqaEVvB2ZK"
   },
   "outputs": [],
   "source": [
    "# there are some things from https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html\n",
    "class TrDecoder(nn.Module):\n",
    "    def __init__(self, dec_embed_dim, dec_depth, dec_n_heads, dec_feedforward_dim):\n",
    "        super(TrDecoder, self).__init__()\n",
    "        \n",
    "        self.dec_embed_dim = dec_embed_dim\n",
    "        self.dec_depth = dec_depth\n",
    "        self.dec_n_heads = dec_n_heads\n",
    "        self.dec_feedforward_dim = dec_feedforward_dim\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([nn.TransformerDecoderLayer(dec_embed_dim,\n",
    "                                                                            dec_n_heads,\n",
    "                                                                            dim_feedforward=dec_feedforward_dim,\n",
    "                                                                            activation='gelu') for i in range(dec_depth)])\n",
    "        \n",
    "    def forward(self, embs, mem, seq_mask, pad_mask=None):\n",
    "        embs = embs.transpose(0, 1)\n",
    "\n",
    "        for i in range(self.dec_depth):\n",
    "            embs = self.transformer_layers[i](embs, mem, tgt_mask=seq_mask, memory_key_padding_mask=pad_mask)\n",
    "            \n",
    "        return embs.transpose(0, 1)\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "        \"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "\n",
    "class MDVAE(nn.Module):\n",
    "    def __init__(self, input_size, enc_depth, enc_n_heads, enc_feedforward_dim,\n",
    "                 dec_num_embeds, dec_embed_dim, dec_depth, dec_n_heads, dec_feedforward_dim,\n",
    "                 distr_dim, dict_constants, mode='VAE'):\n",
    "        super(MDVAE, self).__init__()\n",
    "        \n",
    "        # hyperparameters:\n",
    "        self.input_size = input_size\n",
    "        self.enc_depth = enc_depth\n",
    "        self.enc_n_heads = enc_n_heads\n",
    "        self.enc_feedforward_dim = enc_feedforward_dim\n",
    "        self.dec_num_embeds = dec_num_embeds\n",
    "        self.dec_embed_dim = dec_embed_dim\n",
    "        self.dec_depth = dec_depth\n",
    "        self.dec_n_heads = dec_n_heads\n",
    "        self.dec_feedforward_dim = dec_feedforward_dim\n",
    "        self.distr_dim = distr_dim\n",
    "        self.mode = mode\n",
    "        self.DEC_SOS_IND = dict_constants['DEC_SOS_IND']\n",
    "        self.DEC_EOS_IND = dict_constants['DEC_EOS_IND']\n",
    "        self.MAX_SUMMARY_LEN = dict_constants['MAX_SUMMARY_LEN']\n",
    "        self.MAX_DOC_LEN = dict_constants['MAX_DOC_LEN']\n",
    "        \n",
    "        # encoder layers:\n",
    "        self.enc_pos_emb = PositionalEncoding(input_size, 0.0, self.MAX_DOC_LEN)\n",
    "        self.mu_linear = nn.Linear(input_size, distr_dim)\n",
    "        self.logsigma_linear = None\n",
    "        if mode == 'VAE':\n",
    "            self.logsigma_linear = nn.Linear(input_size, distr_dim)\n",
    "        elif mode != 'AE':\n",
    "            raise ValueError('Unknown mode: must be \"VAE\" or \"AE\", not {}'.format(mode))\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=input_size,\n",
    "                                               nhead=enc_n_heads,\n",
    "                                               dim_feedforward=enc_feedforward_dim,\n",
    "                                               activation=\"gelu\")\n",
    "        self.document_encoder = nn.TransformerEncoder(enc_layer, num_layers=enc_depth)\n",
    "        self.doc_encoder_linear = nn.Linear(input_size * 2, 1, bias=False)\n",
    "        \n",
    "        # decoder layers:\n",
    "        self.decoder_emb = nn.Embedding(dec_num_embeds, dec_embed_dim)\n",
    "        self.dec_pos_emb = PositionalEncoding(dec_embed_dim, 0.0, self.MAX_SUMMARY_LEN)\n",
    "        self.dec_enc_to_mem = nn.Linear(input_size, dec_embed_dim)\n",
    "        self.dec_latent_to_add_mem = nn.Linear(distr_dim, dec_embed_dim)\n",
    "        self.decoder = TrDecoder(self.dec_embed_dim, self.dec_depth, self.dec_n_heads, self.dec_feedforward_dim)\n",
    "        seq_mask = self.decoder.generate_square_subsequent_mask(self.MAX_SUMMARY_LEN)\n",
    "        self.register_buffer('seq_mask', seq_mask)\n",
    "        self.decoder_linear1 = nn.Linear(dec_embed_dim, dec_embed_dim)\n",
    "        self.decoder_linear2 = nn.Linear(dec_embed_dim, dec_num_embeds)\n",
    "    \n",
    "    def encode_vae(self, inputs, pad_mask=None):\n",
    "        # inputs: (n_docs, n_tokens, input_size)\n",
    "\n",
    "        # BERT embeddings per document + positional embeddings to document embeddings:\n",
    "        x = self.enc_pos_emb(inputs).transpose(0, 1)\n",
    "        x = self.document_encoder(x, src_key_padding_mask=pad_mask).transpose(0, 1)\n",
    "        if pad_mask is None:\n",
    "            doc_embeds = torch.mean(x, dim=1)\n",
    "        else:\n",
    "            not_pad_mask = torch.logical_not(pad_mask)\n",
    "            doc_embeds = torch.sum(x * not_pad_mask.unsqueeze(2), dim=1) / torch.sum(not_pad_mask, dim=1).view(-1, 1)\n",
    "\n",
    "        # document embeddings to set-of-documents embedding:\n",
    "        if doc_embeds.shape[0] == 1:       # only 1 document in inputs\n",
    "            set_of_docs_emb = doc_embeds\n",
    "        else:                              # more than 1 document in inputs\n",
    "            d_sum = torch.sum(doc_embeds, dim=0)\n",
    "            d_conc = torch.cat((doc_embeds, d_sum.view(1, -1).expand(doc_embeds.shape[0], -1)), -1)\n",
    "            weights = self.doc_encoder_linear(d_conc)\n",
    "            weights = F.softmax(weights, dim=0)\n",
    "            set_of_docs_emb = torch.mm(weights.view(1, -1), doc_embeds)\n",
    "            \n",
    "        # set-of-documents embedding to mu and logvar:\n",
    "        mu = self.mu_linear(set_of_docs_emb)\n",
    "        logsigma = self.logsigma_linear(set_of_docs_emb)\n",
    "        if pad_mask is None:\n",
    "            return mu, logsigma, (x.reshape((-1, x.shape[2])).unsqueeze(1), None)\n",
    "        else:\n",
    "            return mu, logsigma, (x.reshape((-1, x.shape[2])).unsqueeze(1), pad_mask.reshape((1, -1)))\n",
    "    \n",
    "    def encode_ae(self, inputs, pad_mask=None):\n",
    "        # inputs: (n_docs, n_tokens, input_size)\n",
    "        \n",
    "        # BERT embeddings per document + positional embeddings to document embeddings:\n",
    "        x = self.enc_pos_emb(inputs).transpose(0, 1)\n",
    "        x = self.document_encoder(x, src_key_padding_mask=pad_mask).transpose(0, 1)\n",
    "        if pad_mask is None:\n",
    "            doc_embeds = torch.mean(x, dim=1)\n",
    "        else:\n",
    "            not_pad_mask = torch.logical_not(pad_mask)\n",
    "            doc_embeds = torch.sum(x * not_pad_mask.unsqueeze(2), dim=1) / torch.sum(not_pad_mask, dim=1).view(-1, 1)\n",
    "        \n",
    "        # document embeddings to set-of-documents embedding:\n",
    "        if doc_embeds.shape[0] == 1:       # only 1 document in inputs\n",
    "            set_of_docs_emb = doc_embeds\n",
    "        else:                              # more than 1 document in inputs\n",
    "            d_sum = torch.sum(doc_embeds, dim=0)\n",
    "            d_conc = torch.cat((doc_embeds, d_sum.view(1, -1).expand(doc_embeds.shape[0], -1)), -1)\n",
    "            weights = self.doc_encoder_linear(d_conc)\n",
    "            weights = F.softmax(weights, dim=0)\n",
    "            set_of_docs_emb = torch.mm(weights.view(1, -1), doc_embeds)\n",
    "        \n",
    "        # set-of-documents embedding to mu:\n",
    "        mu = self.mu_linear(set_of_docs_emb)\n",
    "        if pad_mask is None:\n",
    "            return mu, (x.reshape((-1, x.shape[2])).unsqueeze(1), None)\n",
    "        else:\n",
    "            return mu, (x.reshape((-1, x.shape[2])).unsqueeze(1), pad_mask.reshape((1, -1)))\n",
    "    \n",
    "    def reparam_sample(self, mu, logsigma):\n",
    "        std = torch.exp(0.5 * logsigma)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    \n",
    "    def decode(self, z, memory, pad_mask=None, target_summary=None, max_summary_len=None):\n",
    "        # teacher forcing:\n",
    "        if target_summary is not None:\n",
    "            if target_summary.shape[1] > self.MAX_SUMMARY_LEN:\n",
    "                raise ValueError(\"target_summary's len must be <= MAX_SUMMARY_LEN = {}\".format(self.MAX_SUMMARY_LEN))\n",
    "            embs = self.decoder_emb(target_summary)\n",
    "            embs = self.dec_pos_emb(embs)\n",
    "            mem = self.dec_enc_to_mem(memory)\n",
    "            add_mem = self.dec_latent_to_add_mem(z.view(1, 1, -1))\n",
    "            embs = embs + add_mem\n",
    "            decoded = self.decoder(embs, mem=mem, seq_mask=self.seq_mask[:embs.shape[1], :embs.shape[1]], pad_mask=pad_mask)\n",
    "            return F.log_softmax(self.decoder_linear2(F.relu(self.decoder_linear1(decoded))), dim=-1)\n",
    "        # autoregressive one-by-one:\n",
    "        else:\n",
    "            if max_summary_len is None:\n",
    "                max_len = self.MAX_SUMMARY_LEN\n",
    "            else:\n",
    "                max_len = min(max_summary_len, self.MAX_SUMMARY_LEN)\n",
    "            inds = [self.DEC_SOS_IND]\n",
    "            embs = self.decoder_emb(torch.tensor([inds], dtype=torch.long, device=z.device))\n",
    "            embs = self.dec_pos_emb(embs)\n",
    "            mem = self.dec_enc_to_mem(memory)\n",
    "            add_mem = self.dec_latent_to_add_mem(z.view(1, 1, -1))\n",
    "            embs = embs + add_mem\n",
    "            log_probs = None\n",
    "            for i in range(max_len - 2):\n",
    "                decoded = self.decoder(embs, mem=mem, seq_mask=self.seq_mask[:embs.shape[1], :embs.shape[1]], pad_mask=pad_mask)\n",
    "                log_probs = F.log_softmax(self.decoder_linear2(F.relu(self.decoder_linear1(decoded))), dim=-1)\n",
    "                next_ind = torch.argmax(log_probs, dim=-1).view(-1)[-1].item()\n",
    "                #next_ind = torch.multinomial(torch.exp(log_probs[0, -1].view(-1)), 1).item()\n",
    "                if next_ind == self.DEC_EOS_IND:\n",
    "                    return log_probs\n",
    "                inds.append(next_ind)\n",
    "                embs = self.decoder_emb(torch.tensor([inds], dtype=torch.long, device=z.device))\n",
    "                embs = self.dec_pos_emb(embs)\n",
    "                embs = embs + add_mem\n",
    "            return log_probs\n",
    "            \n",
    "    def forward(self, inputs, pad_mask=None, summary=None, max_summary_len=None, deterministic=False):\n",
    "        # inputs: (n_docs, n_sentences, input_size)\n",
    "        \n",
    "        if self.mode == 'VAE':\n",
    "            if not deterministic:\n",
    "                mu, logsigma, (mem, mem_pad) = self.encode_vae(inputs, pad_mask)\n",
    "                z = self.reparam_sample(mu, logsigma)\n",
    "                return [self.decode(z, mem, mem_pad, summary, max_summary_len), mu, logsigma]\n",
    "            else:\n",
    "                mu, logsigma, (mem, mem_pad) = self.encode_vae(inputs, pad_mask)\n",
    "                return [self.decode(mu, mem, mem_pad, summary, max_summary_len), mu, logsigma]\n",
    "        else:\n",
    "            z, (mem, mem_pad) = self.encode_ae(inputs, pad_mask)\n",
    "            return self.decode(z, mem, mem_pad, summary, max_summary_len), z\n",
    "    \n",
    "    # generate text summary\n",
    "    def summarize(self, inp, dec_vocab_ind2word, pad_mask=None, deterministic=True, max_summary_len=None):  \n",
    "        # deterministic: latent vector z equals mu if True, else z is sampled\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            m = self.training\n",
    "            self.eval()\n",
    "            if deterministic or self.mode == 'AE':\n",
    "                z, (mem, mem_pad) = self.encode_ae(inp, pad_mask)\n",
    "            else:\n",
    "                mu, logsigma, (mem, mem_pad) = self.encode_vae(inp, pad_mask)\n",
    "                z = self.reparam_sample(mu, logsigma)\n",
    "            summary_inds = torch.reshape(torch.argmax(self.decode(z, mem, mem_pad, None, max_summary_len), dim=-1), (-1,))\n",
    "            summary = ''\n",
    "            for ind in summary_inds:\n",
    "                summary += dec_vocab_ind2word[ind.item()] + ' '\n",
    "            self.train(m)\n",
    "            return summary[:-1]\n",
    "    \n",
    "    def full_vae_loss(self, pred, target, mu, logsigma, reduction='mean'):\n",
    "        nll = F.nll_loss(pred.squeeze(0), target.view(-1), reduction=reduction)\n",
    "        kl = -0.5 * torch.sum(1 + logsigma - mu**2 - logsigma.exp())\n",
    "        if reduction == 'mean':\n",
    "            kl_weight = 1 / target.view(-1).shape[0]\n",
    "        else:\n",
    "            kl_weight = 1\n",
    "        full = nll + kl_weight * kl\n",
    "        #full = nll + kl\n",
    "        return full, nll, kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z334P6ZtB2ZN"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItvccOUYB2ZN"
   },
   "outputs": [],
   "source": [
    "dict_constants = {}\n",
    "dict_constants['DEC_SOS_IND'] = DEC_SOS_IND\n",
    "dict_constants['DEC_EOS_IND'] = DEC_EOS_IND\n",
    "dict_constants['MAX_SUMMARY_LEN'] = MAX_SUMMARY_LEN\n",
    "dict_constants['MAX_DOC_LEN'] = MAX_DOC_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQhtbI7_B2ZQ"
   },
   "outputs": [],
   "source": [
    "model = MDVAE(input_size=BERT_DIM,\n",
    "              enc_depth=4,\n",
    "              enc_n_heads=8,\n",
    "              enc_feedforward_dim=2048,\n",
    "              dec_num_embeds=dec_vocab_size,\n",
    "              dec_embed_dim=256,\n",
    "              dec_depth=4,\n",
    "              dec_n_heads=8,\n",
    "              dec_feedforward_dim=1024,\n",
    "              distr_dim=256,\n",
    "              dict_constants=dict_constants,\n",
    "              mode='VAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1589908541459,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "qpNTosS5B2ZS",
    "outputId": "b5972edf-a158-457b-f988-b35268ffa0ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52281743"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1589908542170,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "roIpFxbxB2ZV",
    "outputId": "ec344a79-2cd5-42c1-c7c3-b0d8cb52cea4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52281743"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xScjF-Sl2D2l"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('vae_attn/checkpoints/epoch{}.pt'.format(14))\n",
    "losses_log = torch.load('vae_attn/losses_log.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5AHaFLLB2ZX"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34qmynphbYWF"
   },
   "outputs": [],
   "source": [
    "def test_vae(model, data, summaries):\n",
    "    model.eval()\n",
    "    predicted_summaries = []\n",
    "    ref_summaries = []\n",
    "    inds = np.arange(len(data))\n",
    "    num_batches = int(np.ceil(len(data) / BATCH_SIZE))\n",
    "    with torch.no_grad():\n",
    "        for i in tnrange(num_batches):\n",
    "\n",
    "            batch = tokenized2batch(data, inds[i * BATCH_SIZE:(i + 1) * BATCH_SIZE], bert_model, bert_tokenizer)\n",
    "\n",
    "            for j in range(len(batch)):\n",
    "                docs, pad_mask = batch[j]\n",
    "                summary = summaries[inds[i * BATCH_SIZE + j]].cuda()\n",
    "                predicted_summaries.append(model.summarize(docs, sum_lang.id2word, pad_mask=pad_mask, deterministic=True))\n",
    "                ref_summaries.append(' '.join([sum_lang.id2word[w.item()] for w in summary[0]]))\n",
    "\n",
    "            del batch\n",
    "\n",
    "     \n",
    "    return predicted_summaries, ref_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "82066378cc9c481699b6f64fb2709fa6",
      "9c8e66e5738e4d7da177898ff284bb63",
      "b8e6ce9aa4344b41bbecf38dcf500d40",
      "5d14452ed54f427e83d6fa8d15057831",
      "22a93828151349a2881b0e868fa984ca",
      "d931f6c4d62547ba8690d088ab43fb80",
      "1ce02d0fd47940d68fc2f57bf66950fd",
      "4f070af9e59d42f3911a26253c8f5543"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15042026,
     "status": "ok",
     "timestamp": 1589923726738,
     "user": {
      "displayName": "Денис Бурштеин",
      "photoUrl": "",
      "userId": "00444690313210585410"
     },
     "user_tz": -180
    },
    "id": "153_a-5ED0dM",
    "outputId": "c7c3ffc5-8021-486a-8110-98e373c154e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82066378cc9c481699b6f64fb2709fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=352.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sum, ref_sum = test_vae(model, test, test_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGziS0LaEieC"
   },
   "outputs": [],
   "source": [
    "torch.save(pred_sum, 'vae_attn/test_predictions.pt')\n",
    "torch.save(ref_sum, 'vae_attn/refs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJ8-88promHI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "MDVAE attn testing (vae).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09efaf2f3e7f43df9b36d5a72d75be85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d0f78ce177140c1b9a040a346ad2010": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ac5121ecf1f49d7b2350f1ba868030f",
       "IPY_MODEL_ca7e3ea397814abba8c20bbbb7b215f5"
      ],
      "layout": "IPY_MODEL_a2bce06c77fc4cf5b550cb99de9c4492"
     }
    },
    "14933fc904ea4ddbb98c35f2fbecf73a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_548d5ce503ba41819891d08718ae527a",
      "placeholder": "​",
      "style": "IPY_MODEL_6804545ef6ed4f52b8cad1ab07b866dd",
      "value": " 433/433 [00:00&lt;00:00, 3.64kB/s]"
     }
    },
    "1788b3958b344224a5e50de99ad57c8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ac5121ecf1f49d7b2350f1ba868030f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ad0a59ed03e409fbe018c6e886f6b92",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ecbf5dae3bea42c484d0fa3ad955024d",
      "value": 231508
     }
    },
    "1ad0a59ed03e409fbe018c6e886f6b92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ce02d0fd47940d68fc2f57bf66950fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e98a88643d74ad1933416d41c27e6a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94e99194c94347aeaf7996a95d668ea4",
      "placeholder": "​",
      "style": "IPY_MODEL_4b791fdb9e724886986d68ff298f9945",
      "value": " 440M/440M [00:09&lt;00:00, 45.5MB/s]"
     }
    },
    "22a93828151349a2881b0e868fa984ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "23c287216acc4a71b80244f2137c0fde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ad92cfc638549d1b21fad4595d427d1",
       "IPY_MODEL_14933fc904ea4ddbb98c35f2fbecf73a"
      ],
      "layout": "IPY_MODEL_e27b53c544f041409a376f39bbc67673"
     }
    },
    "29d4d28987f64112bb8aea24b2b16679": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cbe3ce456a24364a96ed320cc66c47e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29d4d28987f64112bb8aea24b2b16679",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_932584e0b8f74b489ac86a39ddf12307",
      "value": 440473133
     }
    },
    "32025c95903c4dc2811ca543b2ff05c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cbe3ce456a24364a96ed320cc66c47e",
       "IPY_MODEL_1e98a88643d74ad1933416d41c27e6a2"
      ],
      "layout": "IPY_MODEL_714669ac5e784e808343438683ac9913"
     }
    },
    "4b791fdb9e724886986d68ff298f9945": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f070af9e59d42f3911a26253c8f5543": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "548d5ce503ba41819891d08718ae527a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d14452ed54f427e83d6fa8d15057831": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f070af9e59d42f3911a26253c8f5543",
      "placeholder": "​",
      "style": "IPY_MODEL_1ce02d0fd47940d68fc2f57bf66950fd",
      "value": " 352/352 [4:10:40&lt;00:00, 42.73s/it]"
     }
    },
    "6804545ef6ed4f52b8cad1ab07b866dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ad92cfc638549d1b21fad4595d427d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09efaf2f3e7f43df9b36d5a72d75be85",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4eb9bb0ef7f4e2da27f2058caeb670a",
      "value": 433
     }
    },
    "714669ac5e784e808343438683ac9913": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82066378cc9c481699b6f64fb2709fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8e6ce9aa4344b41bbecf38dcf500d40",
       "IPY_MODEL_5d14452ed54f427e83d6fa8d15057831"
      ],
      "layout": "IPY_MODEL_9c8e66e5738e4d7da177898ff284bb63"
     }
    },
    "932584e0b8f74b489ac86a39ddf12307": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "94e99194c94347aeaf7996a95d668ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c8e66e5738e4d7da177898ff284bb63": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2bce06c77fc4cf5b550cb99de9c4492": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a81972552cbf4ad0a13c7a40e41963c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8e6ce9aa4344b41bbecf38dcf500d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d931f6c4d62547ba8690d088ab43fb80",
      "max": 352,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22a93828151349a2881b0e868fa984ca",
      "value": 352
     }
    },
    "c4eb9bb0ef7f4e2da27f2058caeb670a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ca7e3ea397814abba8c20bbbb7b215f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1788b3958b344224a5e50de99ad57c8a",
      "placeholder": "​",
      "style": "IPY_MODEL_a81972552cbf4ad0a13c7a40e41963c4",
      "value": " 232k/232k [00:00&lt;00:00, 298kB/s]"
     }
    },
    "d931f6c4d62547ba8690d088ab43fb80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e27b53c544f041409a376f39bbc67673": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecbf5dae3bea42c484d0fa3ad955024d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
